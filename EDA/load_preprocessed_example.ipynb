{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa4fe349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74520d4",
   "metadata": {},
   "source": [
    "## Method 1: Direct Load (Manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b0bdffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Classification Data Loaded:\n",
      "  X_train: (168834, 34)\n",
      "  X_test: (42209, 34)\n",
      "  y_train: (168834,)\n",
      "  y_test: (42209,)\n"
     ]
    }
   ],
   "source": [
    "# Load binary classification data\n",
    "with open('processed_artifacts/binary_preprocessed.pkl', 'rb') as f:\n",
    "    binary_artifacts = pickle.load(f)\n",
    "\n",
    "X_train_bin = binary_artifacts['X_train']\n",
    "X_test_bin = binary_artifacts['X_test']\n",
    "y_train_bin = binary_artifacts['y_train']\n",
    "y_test_bin = binary_artifacts['y_test']\n",
    "\n",
    "print(f\"Binary Classification Data Loaded:\")\n",
    "print(f\"  X_train: {X_train_bin.shape}\")\n",
    "print(f\"  X_test: {X_test_bin.shape}\")\n",
    "print(f\"  y_train: {y_train_bin.shape}\")\n",
    "print(f\"  y_test: {y_test_bin.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "161d468b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class Classification Data Loaded:\n",
      "  X_train: (168834, 34)\n",
      "  X_test: (42209, 34)\n",
      "  y_train: (168834,)\n",
      "  y_test: (42209,)\n",
      "  Classes (10): ['backdoor', 'ddos', 'dos', 'injection', 'mitm', 'normal', 'password', 'ransomware', 'scanning', 'xss']\n"
     ]
    }
   ],
   "source": [
    "# Load multi-class classification data\n",
    "with open('processed_artifacts/multiclass_preprocessed.pkl', 'rb') as f:\n",
    "    multi_artifacts = pickle.load(f)\n",
    "\n",
    "X_train_multi = multi_artifacts['X_train']\n",
    "X_test_multi = multi_artifacts['X_test']\n",
    "y_train_multi = multi_artifacts['y_train']\n",
    "y_test_multi = multi_artifacts['y_test']\n",
    "num_classes = multi_artifacts['num_classes']\n",
    "class_names = multi_artifacts['class_names']\n",
    "\n",
    "print(f\"Multi-class Classification Data Loaded:\")\n",
    "print(f\"  X_train: {X_train_multi.shape}\")\n",
    "print(f\"  X_test: {X_test_multi.shape}\")\n",
    "print(f\"  y_train: {y_train_multi.shape}\")\n",
    "print(f\"  y_test: {y_test_multi.shape}\")\n",
    "print(f\"  Classes ({num_classes}): {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba47ac5",
   "metadata": {},
   "source": [
    "## Method 2: Using Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8e15651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ GPU Detected: 1 device(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-10 03:45:44.095746: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ TensorFlow GPU: 1 device(s) available\n"
     ]
    }
   ],
   "source": [
    "# Import utility function from preprocessing_pipeline.py\n",
    "import sys\n",
    "sys.path.insert(0, '/home/elnoersan/Skripsi/Paper/NotebookTODO/EDA')\n",
    "from preprocessing_pipeline import load_preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c739e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded binary artifacts from /home/elnoersan/Skripsi/Paper/NotebookTODO/EDA/processed_artifacts/binary_preprocessed.pkl\n",
      "  Train samples: 168,834\n",
      "  Test samples: 42,209\n",
      "  Features: 34\n"
     ]
    }
   ],
   "source": [
    "# Load binary data\n",
    "binary_data = load_preprocessed_data('binary')\n",
    "\n",
    "X_train_bin = binary_data['X_train']\n",
    "X_test_bin = binary_data['X_test']\n",
    "y_train_bin = binary_data['y_train']\n",
    "y_test_bin = binary_data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f379271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded multiclass artifacts from /home/elnoersan/Skripsi/Paper/NotebookTODO/EDA/processed_artifacts/multiclass_preprocessed.pkl\n",
      "  Train samples: 168,834\n",
      "  Test samples: 42,209\n",
      "  Features: 34\n"
     ]
    }
   ],
   "source": [
    "# Load multi-class data\n",
    "multi_data = load_preprocessed_data('multiclass')\n",
    "\n",
    "X_train_multi = multi_data['X_train']\n",
    "X_test_multi = multi_data['X_test']\n",
    "y_train_multi = multi_data['y_train']\n",
    "y_test_multi = multi_data['y_test']\n",
    "num_classes = multi_data['num_classes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a48396",
   "metadata": {},
   "source": [
    "## Inspect Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61a8008a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Classification Metadata:\n",
      "  n_samples_train: 168834\n",
      "  n_samples_test: 42209\n",
      "  n_features_original: 35\n",
      "  n_features_encoded: 881\n",
      "  n_features_final: 34\n",
      "  test_size: 0.2\n",
      "  random_state: 42\n",
      "  feature_selection_method: VarianceThreshold\n"
     ]
    }
   ],
   "source": [
    "print(\"Binary Classification Metadata:\")\n",
    "for key, value in binary_data['metadata'].items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "591fca67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class Classification Metadata:\n",
      "  n_samples_train: 168834\n",
      "  n_samples_test: 42209\n",
      "  n_features_original: 35\n",
      "  n_features_encoded: 881\n",
      "  n_features_final: 34\n",
      "  test_size: 0.2\n",
      "  random_state: 42\n",
      "  num_classes: 10\n",
      "  feature_selection_method: VarianceThreshold\n"
     ]
    }
   ],
   "source": [
    "print(\"Multi-class Classification Metadata:\")\n",
    "for key, value in multi_data['metadata'].items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d03dc69",
   "metadata": {},
   "source": [
    "## Verify Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2042b902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Data Quality:\n",
      "  X_train - NaN: 0, Inf: 0\n",
      "  X_test - NaN: 0, Inf: 0\n",
      "  y_train unique: [0 1]\n",
      "  y_test unique: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN/Inf in binary data\n",
    "print(\"Binary Data Quality:\")\n",
    "print(f\"  X_train - NaN: {np.isnan(X_train_bin).sum()}, Inf: {np.isinf(X_train_bin).sum()}\")\n",
    "print(f\"  X_test - NaN: {np.isnan(X_test_bin).sum()}, Inf: {np.isinf(X_test_bin).sum()}\")\n",
    "print(f\"  y_train unique: {np.unique(y_train_bin)}\")\n",
    "print(f\"  y_test unique: {np.unique(y_test_bin)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f06d521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class Data Quality:\n",
      "  X_train - NaN: 0, Inf: 0\n",
      "  X_test - NaN: 0, Inf: 0\n",
      "  y_train unique: [0 1 2 3 4 5 6 7 8 9]\n",
      "  y_test unique: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN/Inf in multi-class data\n",
    "print(\"Multi-class Data Quality:\")\n",
    "print(f\"  X_train - NaN: {np.isnan(X_train_multi).sum()}, Inf: {np.isinf(X_train_multi).sum()}\")\n",
    "print(f\"  X_test - NaN: {np.isnan(X_test_multi).sum()}, Inf: {np.isinf(X_test_multi).sum()}\")\n",
    "print(f\"  y_train unique: {np.unique(y_train_multi)}\")\n",
    "print(f\"  y_test unique: {np.unique(y_test_multi)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aac098",
   "metadata": {},
   "source": [
    "## Ready for Training!\n",
    "\n",
    "Now you can use `X_train_bin`, `X_test_bin`, `y_train_bin`, `y_test_bin` directly in your FL notebook.\n",
    "\n",
    "**Time saved:** ~5-10 minutes per notebook run!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
